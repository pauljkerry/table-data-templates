{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73f728b-1ec5-48a4-bfd6-c51776b3e7a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T14:11:26.759213Z",
     "iopub.status.busy": "2025-10-05T14:11:26.758004Z",
     "iopub.status.idle": "2025-10-05T14:11:26.783120Z",
     "shell.execute_reply": "2025-10-05T14:11:26.782433Z",
     "shell.execute_reply.started": "2025-10-05T14:11:26.759129Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import wandb\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "from src.utils.telegram import send_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a3514-4e34-4a71-bc6d-e091221b1712",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "579e3aba-256f-4460-b871-8c1a90ca9ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T14:11:28.431319Z",
     "iopub.status.busy": "2025-10-05T14:11:28.430800Z",
     "iopub.status.idle": "2025-10-05T14:11:28.444253Z",
     "shell.execute_reply": "2025-10-05T14:11:28.443775Z",
     "shell.execute_reply.started": "2025-10-05T14:11:28.431304Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    data_id: str = \"057\"\n",
    "    model_name: str = \"ag\"\n",
    "\n",
    "    # AutoGluon\n",
    "    label: str = \"target\"\n",
    "    problem_type: str = \"binary\"\n",
    "    eval_metric: str = \"roc_auc\"\n",
    "    ag_path: str = \"../../artifacts\"\n",
    "\n",
    "    time_limit: int = 3600*10\n",
    "    presets: str = \"best_quality\"\n",
    "    auto_stack: bool = True\n",
    "\n",
    "    study_name = f\"{model_name}_{data_id}\"\n",
    "\n",
    "\n",
    "cfg = Config()\n",
    "load_dotenv(dotenv_path=\"../../.env\")\n",
    "\n",
    "feature_dir = Path(f\"../../artifacts/features/{cfg.data_id}\")\n",
    "\n",
    "with open(feature_dir / \"meta.json\", \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "train_paths = meta[\"train_paths\"]\n",
    "test_paths = meta[\"test_paths\"]\n",
    "level = meta[\"level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4baf4596-7571-418d-b96f-ae14b816cdde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T14:11:29.443945Z",
     "iopub.status.busy": "2025-10-05T14:11:29.443736Z",
     "iopub.status.idle": "2025-10-05T14:11:30.942414Z",
     "shell.execute_reply": "2025-10-05T14:11:30.941916Z",
     "shell.execute_reply.started": "2025-10-05T14:11:29.443931Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/hanse/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkaitookano\u001b[0m (\u001b[33mkaitookano-waseda-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../../artifacts/wandb/run-20251005_231129-lfqdb56o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kaitookano-waseda-university/playground-series-s5e8/runs/lfqdb56o' target=\"_blank\">057</a></strong> to <a href='https://wandb.ai/kaitookano-waseda-university/playground-series-s5e8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kaitookano-waseda-university/playground-series-s5e8' target=\"_blank\">https://wandb.ai/kaitookano-waseda-university/playground-series-s5e8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kaitookano-waseda-university/playground-series-s5e8/runs/lfqdb56o' target=\"_blank\">https://wandb.ai/kaitookano-waseda-university/playground-series-s5e8/runs/lfqdb56o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === WANDB ===\n",
    "wandb_project = os.environ.get(\"COMPETITION_NAME\")\n",
    "wandb.login(key=os.environ.get(\"WANDB_API_KEY\"))\n",
    "\n",
    "run = wandb.init(\n",
    "    project=wandb_project,\n",
    "    group=cfg.study_name,\n",
    "    name=cfg.data_id,\n",
    "    job_type=\"cv_training\",\n",
    "    tags=[cfg.model_name, level],\n",
    "    config={\n",
    "        \"data_id\": cfg.data_id,\n",
    "        \"level\": level,\n",
    "        \"model\": cfg.model_name,\n",
    "    },\n",
    "    dir=\"../../artifacts\",\n",
    "    reinit=\"finish_previous\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7027afe-279b-4762-ab04-f1c05a890670",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-05T14:20:30.119506Z",
     "iopub.status.busy": "2025-10-05T14:20:30.118944Z",
     "iopub.status.idle": "2025-10-06T01:27:58.479892Z",
     "shell.execute_reply": "2025-10-06T01:27:58.478465Z",
     "shell.execute_reply.started": "2025-10-05T14:20:30.119491Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"../../artifacts\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025\n",
      "CPU Count:          24\n",
      "Memory Avail:       15.19 GB / 23.47 GB (64.7%)\n",
      "Disk Space Avail:   754.04 GB / 1006.85 GB (74.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 9000s of the 36000s of remaining time (25%).\n",
      "2025-10-05 23:20:31,066\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-10-05 23:20:32,486\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/home/hanse/kaggle/binary-bank/artifacts/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Beginning AutoGluon training ... Time limit = 8998s\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m AutoGluon will save models to \"/home/hanse/kaggle/binary-bank/artifacts/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Train Data Rows:    666666\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Train Data Columns: 623\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Label Column:       target\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tAvailable Memory:                    13343.14 MB\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tTrain Data (Original)  Memory Usage: 1586.91 MB (11.9% of available memory)\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tWarning: Data size prior to feature transformation consumes 11.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tUnused Original Features (Count: 5): ['default_ce', 'loan_ce', 'duration_adiff_previous', 'duration_previous_min', 'duration_previous_max']\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\t('float', []) : 2 | ['default_ce', 'loan_ce']\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\t('int', [])   : 3 | ['duration_adiff_previous', 'duration_previous_min', 'duration_previous_max']\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\t('float', []) : 481 | ['target_mean_by_job', 'target_mean_by_marital', 'target_mean_by_education', 'target_mean_by_default', 'target_mean_by_housing', ...]\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\t('int', [])   : 137 | ['age', 'balance', 'day', 'duration', 'campaign', ...]\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\t('float', [])     : 477 | ['target_mean_by_job', 'target_mean_by_marital', 'target_mean_by_education', 'target_mean_by_default', 'target_mean_by_housing', ...]\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\t('int', [])       : 137 | ['age', 'balance', 'day', 'duration', 'campaign', ...]\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\t('int', ['bool']) :   4 | ['orig_target_mean_by_default', 'orig_target_mean_by_housing', 'orig_target_mean_by_loan', 'housing_ce']\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t28.6s = Fit runtime\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t618 features in original data used to generate 618 features in processed data.\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tTrain Data (Processed) Memory Usage: 1566.57 MB (11.8% of available memory)\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Data preprocessing and feature engineering runtime = 30.43s ...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5976.71s of the 8967.30s of remaining time.\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tWarning: Potentially not enough memory to safely train model. Estimated to require 10.094 GB out of 11.412 GB available memory (88.451%)... (90.000% of avail memory is the max safe size)\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.23 to avoid the warning)\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 1 folds in parallel instead (Estimated 88.45% memory usage per fold, 88.45%/80.00% total).\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=12, gpus=0, memory=88.45%)\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tSwitching to pseudo sequential ParallelFoldFittingStrategy to avoid Python memory leakage.\n",
      "\u001b[36m(_dystack pid=10395)\u001b[0m \t\tOverrule this behavior by setting fold_fitting_strategy to 'sequential_local' in ag_args_ensemble when when calling `predictor.fit`\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m\n\u001b[1;32m     15\u001b[0m train \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mread_parquet(train_paths, columns\u001b[38;5;241m=\u001b[39mfeatures)\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[1;32m     17\u001b[0m predictor \u001b[38;5;241m=\u001b[39m TabularPredictor(\n\u001b[1;32m     18\u001b[0m     label\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mlabel,\n\u001b[1;32m     19\u001b[0m     problem_type\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mproblem_type,\n\u001b[1;32m     20\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39meval_metric,\n\u001b[1;32m     21\u001b[0m     path\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mag_path\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_stack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_stack\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m send_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoGluon Training Completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1344\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_stacking:\n\u001b[1;32m   1339\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(\n\u001b[1;32m   1340\u001b[0m         \u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m   1341\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDyStack is enabled (dynamic_stacking=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdynamic_stacking\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1342\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1343\u001b[0m     )\n\u001b[0;32m-> 1344\u001b[0m     num_stack_levels, time_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamic_stacking\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mds_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1345\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1346\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting main fit with num_stack_levels=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_stack_levels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1347\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mFor future fit calls on this dataset, you can skip DyStack to save time: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1348\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`predictor.fit(..., dynamic_stacking=False, num_stack_levels=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_stack_levels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (time_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (time_limit \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1444\u001b[0m, in \u001b[0;36mTabularPredictor._dynamic_stacking\u001b[0;34m(self, ag_fit_kwargs, ag_post_fit_kwargs, validation_procedure, detection_time_frac, holdout_frac, n_folds, n_repeats, memory_safe_fits, clean_up_fits, enable_ray_logging, enable_callbacks, holdout_data)\u001b[0m\n\u001b[1;32m   1441\u001b[0m         _, holdout_data, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_fit_data(train_data\u001b[38;5;241m=\u001b[39mX, tuning_data\u001b[38;5;241m=\u001b[39mholdout_data)\n\u001b[1;32m   1442\u001b[0m         ds_fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mds_fit_context\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ds_fit_context, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msub_fit_custom_ho\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1444\u001b[0m     stacked_overfitting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sub_fit_memory_save_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_ag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_ag_post_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mholdout_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;66;03m# Holdout is false, use (repeated) cross-validation\u001b[39;00m\n\u001b[1;32m   1455\u001b[0m     is_stratified \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;129;01min\u001b[39;00m [BINARY, MULTICLASS]\n",
      "File \u001b[0;32m~/miniconda3/envs/autogluon/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1636\u001b[0m, in \u001b[0;36mTabularPredictor._sub_fit_memory_save_wrapper\u001b[0;34m(self, train_data, time_limit, time_start, ds_fit_kwargs, ag_fit_kwargs, ag_post_fit_kwargs, holdout_data)\u001b[0m\n\u001b[1;32m   1622\u001b[0m \u001b[38;5;66;03m# FIXME: For some reason ray does not treat `num_cpus` and `num_gpus` the same.\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;66;03m#  For `num_gpus`, the process will reserve the capacity and is unable to share it to child ray processes, causing a deadlock.\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;66;03m#  For `num_cpus`, the value is completely ignored by children, and they can even use more num_cpus than the parent.\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;66;03m#  Because of this, num_gpus is set to 0 here to avoid a deadlock, but num_cpus does not need to be changed.\u001b[39;00m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;66;03m#  For more info, refer to Ray documentation: https://docs.ray.io/en/latest/ray-core/tasks/nested-tasks.html#yielding-resources-while-blocked\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m ref \u001b[38;5;241m=\u001b[39m sub_fit_caller\u001b[38;5;241m.\u001b[39moptions(num_cpus\u001b[38;5;241m=\u001b[39mnum_cpus, num_gpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mremote(\n\u001b[1;32m   1628\u001b[0m     predictor\u001b[38;5;241m=\u001b[39mpredictor_ref,\n\u001b[1;32m   1629\u001b[0m     train_data\u001b[38;5;241m=\u001b[39mtrain_data_ref,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1634\u001b[0m     holdout_data\u001b[38;5;241m=\u001b[39mholdout_data_ref,\n\u001b[1;32m   1635\u001b[0m )\n\u001b[0;32m-> 1636\u001b[0m finished, unfinished \u001b[38;5;241m=\u001b[39m \u001b[43m_ds_ray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mref\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1637\u001b[0m stacked_overfitting, ho_leaderboard, exception \u001b[38;5;241m=\u001b[39m _ds_ray\u001b[38;5;241m.\u001b[39mget(finished[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1639\u001b[0m \u001b[38;5;66;03m# TODO: This is present to ensure worker logs are properly logged and don't get skipped / printed out of order.\u001b[39;00m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;66;03m#  Ideally find a faster way to do this that doesn't introduce a 100 ms overhead.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/autogluon/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/autogluon/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/autogluon/lib/python3.10/site-packages/ray/_private/worker.py:3013\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   3011\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m   3012\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m-> 3013\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3529\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/includes/common.pxi:83\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "all_cols = pl.read_parquet(train_paths, n_rows=0).columns\n",
    "\n",
    "meta = {\n",
    "    c\n",
    "    for c in (\"row_id\", \"weight\")\n",
    "    if c and c in all_cols\n",
    "}\n",
    "pat = re.compile(r\"^\\d+fold(?:-[A-Za-z0-9]+)?$\")\n",
    "features = [\n",
    "    c for c in all_cols\n",
    "    if c not in meta and not pat.fullmatch(c)\n",
    "]\n",
    "\n",
    "train = pl.read_parquet(train_paths, columns=features).to_pandas()\n",
    "\n",
    "predictor = TabularPredictor(\n",
    "    label=cfg.label,\n",
    "    problem_type=cfg.problem_type,\n",
    "    eval_metric=cfg.eval_metric,\n",
    "    path=cfg.ag_path\n",
    ")\n",
    "predictor.fit(\n",
    "    train,\n",
    "    time_limit=cfg.time_limit,\n",
    "    presets=cfg.presets,\n",
    "    auto_stack=cfg.auto_stack\n",
    ")\n",
    "\n",
    "send_message(\"AutoGluon Training Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2236fd51-ec4d-4d1d-a6d9-3c7deeab9156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
