{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dede9c68-9c41-4f24-a5bc-1b139dd714fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:14:24.282096Z",
     "iopub.status.busy": "2025-10-04T01:14:24.281867Z",
     "iopub.status.idle": "2025-10-04T01:14:28.158444Z",
     "shell.execute_reply": "2025-10-04T01:14:28.158040Z",
     "shell.execute_reply.started": "2025-10-04T01:14:24.282084Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "from collections import Counter\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "\n",
    "import ipynbname\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "from src.utils.target_encoding import target_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e2ee8-c192-41a6-965f-af38fa23bc87",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d6ad7a-72fe-4727-b888-bf3095c0d43a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:14:29.045918Z",
     "iopub.status.busy": "2025-10-04T01:14:29.045699Z",
     "iopub.status.idle": "2025-10-04T01:14:29.057566Z",
     "shell.execute_reply": "2025-10-04T01:14:29.057040Z",
     "shell.execute_reply.started": "2025-10-04T01:14:29.045907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem = ipynbname.path().stem\n",
    "m = re.search(r\"(\\d+)$\", stem)\n",
    "\n",
    "ID = m.group(1)\n",
    "SEED = 42\n",
    "LEVEL = \"l1\"\n",
    "FEATURE_DIR = Path(f\"../../artifacts/features/{ID}\")\n",
    "\n",
    "os.makedirs(FEATURE_DIR, exist_ok=True)\n",
    "\n",
    "pl.Config.set_tbl_rows(500)\n",
    "pl.Config.set_tbl_cols(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e209e14a-75ee-45ae-8596-16f1b7a5551d",
   "metadata": {},
   "source": [
    "### Urils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bae812c-9059-4f2b-b7de-b9f5e63f76fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:26:53.072220Z",
     "iopub.status.busy": "2025-10-04T01:26:53.072007Z",
     "iopub.status.idle": "2025-10-04T01:26:53.080987Z",
     "shell.execute_reply": "2025-10-04T01:26:53.080544Z",
     "shell.execute_reply.started": "2025-10-04T01:26:53.072212Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_info(\n",
    "    train: pl.DataFrame,\n",
    "    test: pl.DataFrame\n",
    ") -> tuple[float, float, float]:\n",
    "    train_mem = sum(train[col].to_numpy().nbytes for col in train.columns) / 1024**3\n",
    "    test_mem = sum(test[col].to_numpy().nbytes for col in test.columns) / 1024**3\n",
    "\n",
    "    print(\"=== Shape & Memory ===\")\n",
    "    print(f\"Train Shape: {train.shape}, Test Shape: {test.shape}\")\n",
    "    print(f\"Train Memory: {train_mem:.2f} GB, Test Memory: {test_mem:.2f} GB\\n\")\n",
    "\n",
    "    dtype_counts = Counter([str(dt) for dt in train.dtypes])\n",
    "\n",
    "    n_cat = None\n",
    "    print(\"=== DTypes ===\")\n",
    "    for dtype, cnt in dtype_counts.items():\n",
    "        print(f\"{dtype}: {cnt}\")\n",
    "        if dtype == \"Categorical\":\n",
    "            n_cat = cnt\n",
    "    return train_mem, test_mem, n_cat\n",
    "\n",
    "\n",
    "def downcast(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    INT32_MIN, INT32_MAX = -2_147_483_648, 2_147_483_647\n",
    "\n",
    "    df = df.with_columns(pl.col(pl.Float64).cast(pl.Float32))\n",
    "\n",
    "    # Int64で安全に落とせる列だけ選別\n",
    "    int64_cols = [c for c, dt in df.schema.items() if dt == pl.Int64]\n",
    "    safe_cols = []\n",
    "    for c in int64_cols:\n",
    "        mn, mx = df[c].min(), df[c].max()\n",
    "        if mn >= INT32_MIN and mx <= INT32_MAX:\n",
    "            safe_cols.append(c)\n",
    "\n",
    "    # 安全な列だけ Int32 に\n",
    "    if safe_cols:\n",
    "        df = df.with_columns(pl.col(safe_cols).cast(pl.Int32))\n",
    "    return df\n",
    "\n",
    "def target_encoding_orig(\n",
    "    tr_df: pl.DataFrame,\n",
    "    orig_df: pl.DataFrame,\n",
    "    test_df: pl.DataFrame,\n",
    "    key_cols: list[str],\n",
    "    target: str = \"target\",\n",
    "    stats: tuple[str, ...] = (\"mean\", \"std\", \"min\", \"max\", \"median\", \"count\"),\n",
    "    n_splits: int = 5,\n",
    "    seed: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Target Encodingを行う関数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tr_df : pl.DataFrame\n",
    "        Training data\n",
    "    test_df : pl.DataFrame\n",
    "        Unlabeled data\n",
    "    target : str\n",
    "        Targetカラムの列名\n",
    "    cat_cols : list\n",
    "        カテゴリ変数の列名のリスト\n",
    "    n_splits : int\n",
    "        SKFの分割数\n",
    "    seed : int\n",
    "        Random seed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    te_df : pl.DataFrame\n",
    "        Target Encodingを行ったDF\n",
    "    \"\"\"\n",
    "    def stat_names(col: str) -> list[str]:\n",
    "        names = []\n",
    "        if \"mean\" in stats:\n",
    "            names.append(f\"orig_{target}_mean_by_{col}\")\n",
    "        if \"std\" in stats:\n",
    "            names.append(f\"orig_{target}_std_by_{col}\")\n",
    "        if \"min\" in stats:\n",
    "            names.append(f\"orig_{target}_min_by_{col}\")\n",
    "        if \"max\" in stats:\n",
    "            names.append(f\"orig_{target}_max_by_{col}\")\n",
    "        if \"median\" in stats:\n",
    "            names.append(f\"orig_{target}_median_by_{col}\")\n",
    "        if \"count\" in stats:\n",
    "            names.append(f\"orig_{target}_count_by_{col}\")  # 1の個数\n",
    "        return names\n",
    "\n",
    "    all_cols = []\n",
    "    for col in key_cols:\n",
    "        all_cols.extend(stat_names(col))\n",
    "\n",
    "    N_tr, N_te = tr_df.height, test_df.height\n",
    "\n",
    "    te_train = {c: np.zeros(N_tr, dtype=np.float32) for c in all_cols}\n",
    "    te_test = {c: np.zeros(N_te, dtype=np.float32) for c in all_cols}\n",
    "\n",
    "    for col in tqdm(key_cols):\n",
    "        base = orig_df.select([\n",
    "            pl.col(target).mean().alias(\"mean\"),\n",
    "            pl.col(target).std(ddof=1).alias(\"std\"),\n",
    "            pl.col(target).min().alias(\"min\"),\n",
    "            pl.col(target).max().alias(\"max\"),\n",
    "            pl.col(target).median().alias(\"median\"),\n",
    "            (pl.col(target) == 1).sum().alias(\"cnt\"),\n",
    "        ]).to_dicts()[0]\n",
    "\n",
    "        fill_map = {}\n",
    "        for s in stats:\n",
    "            name = f\"orig_{target}_{s}_by_{col}\"\n",
    "            if s == \"count\":\n",
    "                fill_map[name] = 0.0\n",
    "            else:\n",
    "                fill_map[name] = float(base[s])\n",
    "\n",
    "        aggs = []\n",
    "        col_names = []\n",
    "        if \"mean\" in stats:\n",
    "            aggs.append(\n",
    "                pl.col(target).mean().alias(f\"orig_{target}_mean_by_{col}\")\n",
    "            )\n",
    "            col_names.append(f\"orig_{target}_mean_by_{col}\")\n",
    "        if \"std\" in stats:\n",
    "            aggs.append(\n",
    "                pl.col(target).std(ddof=1).alias(f\"orig_{target}_std_by_{col}\")\n",
    "            )\n",
    "            col_names.append(f\"orig_{target}_std_by_{col}\")\n",
    "        if \"min\" in stats:\n",
    "            aggs.append(\n",
    "                pl.col(target).min().alias(f\"orig_{target}_min_by_{col}\")\n",
    "            )\n",
    "            col_names.append(f\"orig_{target}_min_by_{col}\")\n",
    "        if \"max\" in stats:\n",
    "            aggs.append(\n",
    "                pl.col(target).max().alias(f\"orig_{target}_max_by_{col}\")\n",
    "            )\n",
    "            col_names.append(f\"orig_{target}_max_by_{col}\")\n",
    "        if \"median\" in stats:\n",
    "            aggs.append(\n",
    "                pl.col(target).median().alias(f\"orig_{target}_median_by_{col}\")\n",
    "            )\n",
    "            col_names.append(f\"orig_{target}_median_by_{col}\")\n",
    "        if \"count\" in stats:\n",
    "            aggs.append(\n",
    "                (pl.col(target) == 1).sum().alias(f\"orig_{target}_count_by_{col}\")\n",
    "            )\n",
    "            col_names.append(f\"orig_{target}_count_by_{col}\")\n",
    "\n",
    "        grouped_df = (\n",
    "            orig_df.select([col, target])\n",
    "            .group_by(col)\n",
    "            .agg(aggs)\n",
    "        )\n",
    "\n",
    "        # validation\n",
    "        val_mat = (\n",
    "            tr_df.join(\n",
    "                grouped_df.select(col_names + [col]),\n",
    "                on=col,\n",
    "                how=\"left\"\n",
    "            )\n",
    "            .select(col_names)\n",
    "            .with_columns(\n",
    "                [\n",
    "                    pl.col(c).fill_null(fill_map[c]).alias(c)\n",
    "                    for c in col_names\n",
    "                ]\n",
    "            )\n",
    "            .to_numpy()\n",
    "            .astype(dtype=np.float32, copy=False)\n",
    "        )\n",
    "\n",
    "        for j, name in enumerate(col_names):\n",
    "            te_train[name] = val_mat[:, j]\n",
    "\n",
    "        # test\n",
    "        test_mat = (\n",
    "            test_df.join(\n",
    "                grouped_df.select(col_names + [col]),\n",
    "                on=col,\n",
    "                how=\"left\"\n",
    "            )\n",
    "            .select(col_names)\n",
    "            .with_columns(\n",
    "                [\n",
    "                    pl.col(c).fill_null(fill_map[c]).alias(c)\n",
    "                    for c in col_names\n",
    "                ]\n",
    "            )\n",
    "            .to_numpy()\n",
    "            .astype(dtype=np.float32, copy=False)\n",
    "        )\n",
    "        for j, name in enumerate(col_names):\n",
    "            te_test[name] = test_mat[:, j]\n",
    "\n",
    "    del tr_df, orig_df, test_df, grouped_df, val_mat, test_mat\n",
    "\n",
    "    te_tr = pl.DataFrame(te_train)\n",
    "    te_test = pl.DataFrame(te_test)\n",
    "\n",
    "    return pl.concat([te_tr, te_test], how=\"vertical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bdb64f-11ed-47b8-8186-8f887fd6e5aa",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "- 44派生\n",
    "- 2-gram TE(mean, count, std)\n",
    "- orig Targetでも2-gram TE(mean, count, std)\n",
    "- 2-gram CE(without orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c2f120-4143-4b9d-9b01-8306ecb51782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:14:35.418354Z",
     "iopub.status.busy": "2025-10-04T01:14:35.418057Z",
     "iopub.status.idle": "2025-10-04T01:14:35.657495Z",
     "shell.execute_reply": "2025-10-04T01:14:35.657104Z",
     "shell.execute_reply.started": "2025-10-04T01:14:35.418334Z"
    }
   },
   "outputs": [],
   "source": [
    "# === Load Data ===\n",
    "train = pl.read_csv(\"../../input/train.csv\").drop(\"id\")\n",
    "test = pl.read_csv(\"../../input/test.csv\").drop(\"id\")\n",
    "orig = pl.read_parquet(\"../../input/original.parquet\")\n",
    "orig = orig.with_columns(\n",
    "    pl.when(pl.col(\"y\") == \"yes\").then(1)\n",
    "      .when(pl.col(\"y\") == \"no\").then(0)\n",
    "      .otherwise(None)\n",
    "      .alias(\"y\")\n",
    ")\n",
    "\n",
    "y_tr = train[\"y\"].cast(pl.Int8)\n",
    "y_orig = orig[\"y\"].cast(pl.Int8)\n",
    "y_merged = pl.concat([y_tr, y_orig], how=\"vertical\")\n",
    "\n",
    "train = train.drop(\"y\")\n",
    "orig = orig.drop(\"y\")\n",
    "\n",
    "CATS = [col for col in train.columns if train[col].dtype == pl.Utf8]\n",
    "NUMS = [col for col in train.columns if train[col].dtype != pl.Utf8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a0bbd85-afdf-4624-903c-880cd5005fa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:14:36.927625Z",
     "iopub.status.busy": "2025-10-04T01:14:36.927416Z",
     "iopub.status.idle": "2025-10-04T01:14:37.013479Z",
     "shell.execute_reply": "2025-10-04T01:14:37.013134Z",
     "shell.execute_reply.started": "2025-10-04T01:14:36.927612Z"
    }
   },
   "outputs": [],
   "source": [
    "# === 全データを結合 ===\n",
    "all_data = pl.concat([train, test, orig], how=\"vertical\")\n",
    "cat_exprs = [\n",
    "    pl.col(c)\n",
    "    .cast(pl.Categorical)\n",
    "    .to_physical()\n",
    "    .rank(\"dense\")\n",
    "    .cast(pl.Int32)\n",
    "    .alias(c)\n",
    "    for c in CATS\n",
    "]\n",
    "num_df = all_data.select(NUMS)[:len(train)+len(test)]\n",
    "cat_df = all_data.select(\n",
    "    [pl.col(c).cast(pl.Utf8).cast(pl.Categorical) for c in CATS]\n",
    ")[:len(train)+len(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d87ef63-fecd-4e49-986a-cfe95fd92f03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:14:37.740586Z",
     "iopub.status.busy": "2025-10-04T01:14:37.740264Z",
     "iopub.status.idle": "2025-10-04T01:14:37.907793Z",
     "shell.execute_reply": "2025-10-04T01:14:37.907338Z",
     "shell.execute_reply.started": "2025-10-04T01:14:37.740566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job': 12, 'marital': 3, 'education': 4, 'default': 2, 'housing': 2, 'loan': 2, 'contact': 3, 'month': 12, 'poutcome': 4, 'age2': 78, 'balance2': 8590, 'day2': 31, 'duration2': 1824, 'campaign2': 52, 'pdays2': 628, 'previous2': 54}\n"
     ]
    }
   ],
   "source": [
    "# === NUM → CAT ===\n",
    "SIZES = {}\n",
    "\n",
    "num2cat_exprs = [\n",
    "    pl.col(c)\n",
    "    .cast(pl.Utf8)\n",
    "    .cast(pl.Categorical)\n",
    "    .to_physical()\n",
    "    .cast(pl.Int32).alias(f\"{c}2\")\n",
    "    for c in NUMS\n",
    "]\n",
    "\n",
    "num_df2 = all_data.select(num2cat_exprs)\n",
    "NUMS2 = num_df2.columns\n",
    "\n",
    "all_data = all_data.with_columns(cat_exprs + num2cat_exprs)\n",
    "\n",
    "SIZES = all_data.select(\n",
    "    [pl.col(col)\n",
    "     .n_unique()\n",
    "     .alias(col) for col in CATS + NUMS2]\n",
    ").to_dicts()[0]\n",
    "\n",
    "print(SIZES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "148b25a5-9598-49f4-b05b-a85b39a9a1cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:14:38.762752Z",
     "iopub.status.busy": "2025-10-04T01:14:38.762574Z",
     "iopub.status.idle": "2025-10-04T01:14:38.849715Z",
     "shell.execute_reply": "2025-10-04T01:14:38.849143Z",
     "shell.execute_reply.started": "2025-10-04T01:14:38.762741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 120 new columns\n"
     ]
    }
   ],
   "source": [
    "# === 2Comboのペアを作成 ===\n",
    "pairs = list(combinations(CATS + NUMS2, 2))\n",
    "\n",
    "combo_exprs = [(pl.col(c1) * SIZES[c2] + pl.col(c2))\n",
    "               .alias(f\"{c1}_{c2}\") for c1, c2 in pairs]\n",
    "\n",
    "COMBO = [f\"{c1}_{c2}\" for c1, c2 in pairs]\n",
    "\n",
    "combo2_df = all_data.with_columns(combo_exprs)\n",
    "\n",
    "print(f\"Created {len(combo_exprs)} new columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4e8373c-4726-4d4c-b97d-8fc9cb39122b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:26:57.433534Z",
     "iopub.status.busy": "2025-10-04T01:26:57.433374Z",
     "iopub.status.idle": "2025-10-04T01:27:01.604810Z",
     "shell.execute_reply": "2025-10-04T01:27:01.604394Z",
     "shell.execute_reply.started": "2025-10-04T01:26:57.433512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc710365eca467f9403a4cb78d1df95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 408 new columns\n"
     ]
    }
   ],
   "source": [
    "# === originalのTargetでTE ===\n",
    "tr_df = combo2_df[:len(train)]\n",
    "test_df = combo2_df[len(train):len(train)+len(test)]\n",
    "\n",
    "orig_df = combo2_df[len(train)+len(test):]\n",
    "orig_df = orig_df.with_columns(y_orig.alias(\"target\"))\n",
    "\n",
    "te_cols = CATS + NUMS2 + COMBO\n",
    "\n",
    "te_orig = target_encoding_orig(\n",
    "    tr_df,\n",
    "    orig_df,\n",
    "    test_df,\n",
    "    key_cols=te_cols,\n",
    "    target=\"target\",\n",
    "    stats=(\"mean\", \"count\", \"std\")\n",
    ")\n",
    "\n",
    "print(f\"Created {len(te_orig.columns)} new columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e6cfaff-fa85-46cc-bc19-b376163ced15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:27:08.367670Z",
     "iopub.status.busy": "2025-10-04T01:27:08.367530Z",
     "iopub.status.idle": "2025-10-04T01:27:30.540176Z",
     "shell.execute_reply": "2025-10-04T01:27:30.539761Z",
     "shell.execute_reply.started": "2025-10-04T01:27:08.367662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791ce70ebf86439881b4389fa6eed229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7667109078941e9aa2ae759053afa1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee159f3a9184cad9aeb57beb5b3022b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7357c79ec35844628b11a5d46168c918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ac3af12971467d98087de863fce88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26f789822cc4b17a605e16255960b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 408 new columns\n"
     ]
    }
   ],
   "source": [
    "# === Target Encoding ===\n",
    "tr_df = tr_df.with_columns(y_tr.alias(\"target\"))\n",
    "\n",
    "te_df = target_encoding(\n",
    "    tr_df,\n",
    "    test_df,\n",
    "    key_cols=te_cols,\n",
    "    stats=(\"mean\", \"count\", \"std\")\n",
    ")\n",
    "\n",
    "print(f\"Created {len(te_df.columns)} new columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cebd30a8-afc6-4488-90cb-ed99650e42de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:27:31.762278Z",
     "iopub.status.busy": "2025-10-04T01:27:31.762079Z",
     "iopub.status.idle": "2025-10-04T01:27:33.619005Z",
     "shell.execute_reply": "2025-10-04T01:27:33.618501Z",
     "shell.execute_reply.started": "2025-10-04T01:27:31.762266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b5fb0f57cb46efba55c9c62e409d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 136 new columns\n"
     ]
    }
   ],
   "source": [
    "# === Count Encoding\n",
    "combo2_df = combo2_df[:len(train) + len(test)]\n",
    "ce_cols = te_cols\n",
    "ce_dict = {f\"{col}_ce\": np.zeros(all_data.height) for col in ce_cols}\n",
    "\n",
    "for col in tqdm(ce_cols):\n",
    "    counts = combo2_df.group_by(col).agg(pl.len().alias(f\"{col}_ce\"))\n",
    "    joined_df = combo2_df.join(counts, on=col, how=\"left\")\n",
    "    ce_dict[f\"{col}_ce\"] = joined_df[f\"{col}_ce\"]\n",
    "\n",
    "ce_df = pl.DataFrame(ce_dict).with_columns([\n",
    "        pl.col(col).cast(pl.Float32) for col in ce_dict.keys()\n",
    "])\n",
    "\n",
    "print(f\"Created {len(ce_df.columns)} new columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c7a7650-7dca-46a3-9e82-907f62d041dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:27:34.474779Z",
     "iopub.status.busy": "2025-10-04T01:27:34.474527Z",
     "iopub.status.idle": "2025-10-04T01:27:34.478408Z",
     "shell.execute_reply": "2025-10-04T01:27:34.477846Z",
     "shell.execute_reply.started": "2025-10-04T01:27:34.474761Z"
    }
   },
   "outputs": [],
   "source": [
    "# === Dataの統合 ===\n",
    "all_data = pl.concat([\n",
    "    num_df,\n",
    "    te_df,\n",
    "    te_orig,\n",
    "    ce_df\n",
    "], how=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e3a1014-d56f-4c31-aadc-ac9feb200bdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:27:35.602097Z",
     "iopub.status.busy": "2025-10-04T01:27:35.601851Z",
     "iopub.status.idle": "2025-10-04T01:27:35.627566Z",
     "shell.execute_reply": "2025-10-04T01:27:35.627089Z",
     "shell.execute_reply.started": "2025-10-04T01:27:35.602081Z"
    }
   },
   "outputs": [],
   "source": [
    "# === row_id を追加 ===\n",
    "all_data = all_data.with_row_index(\"row_id\")\n",
    "\n",
    "# === Downcast ===\n",
    "all_data = downcast(all_data)\n",
    "\n",
    "# === データを分割 ===\n",
    "tr_df = all_data[:len(train)]\n",
    "test_df = all_data[len(train):len(train)+len(test)]\n",
    "\n",
    "# === targetを追加 ===\n",
    "tr_df = tr_df.with_columns(y_tr.alias(\"target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f108bf5-e7c3-4971-a055-1080c161950b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:27:36.370249Z",
     "iopub.status.busy": "2025-10-04T01:27:36.369985Z",
     "iopub.status.idle": "2025-10-04T01:27:36.605771Z",
     "shell.execute_reply": "2025-10-04T01:27:36.605233Z",
     "shell.execute_reply.started": "2025-10-04T01:27:36.370234Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add Fold Col\n",
    "folds_path = \"../../artifacts/folds/folds.parquet\"\n",
    "pairs = [\n",
    "    (\"skf/k=5/s=42@train\", \"5fold-s42\")\n",
    "]\n",
    "cfgs = [c for c, _ in pairs]\n",
    "rename_map = {c: n for c, n in pairs}\n",
    "\n",
    "# folds をまとめて読み → ワイド化（cfg列を列見出しに）→ 列名をfold_nameにリネーム\n",
    "folds_wide = (\n",
    "    pl.scan_parquet(folds_path)\n",
    "      .filter(pl.col(\"cfg\").is_in(cfgs))\n",
    "      .unique(subset=[\"row_id\", \"cfg\"], keep=\"last\")\n",
    "      .select([\"row_id\", \"cfg\", \"fold\"])\n",
    "      .collect(engine=\"streaming\")\n",
    "      .pivot(values=\"fold\", index=\"row_id\", on=\"cfg\", aggregate_function=\"first\")\n",
    "      .rename(rename_map)\n",
    "      .with_columns(pl.col(\"row_id\").cast(pl.Int32))\n",
    "      .with_columns([pl.all().exclude(\"row_id\").cast(pl.Int8)])  # 型を軽く\n",
    ")\n",
    "\n",
    "# tr_df が DataFrame の場合\n",
    "tr_df = tr_df.join(folds_wide, on=\"row_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "515251e3-7de5-495a-8791-e499e9686986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:27:37.611331Z",
     "iopub.status.busy": "2025-10-04T01:27:37.611036Z",
     "iopub.status.idle": "2025-10-04T01:27:37.617818Z",
     "shell.execute_reply": "2025-10-04T01:27:37.617471Z",
     "shell.execute_reply.started": "2025-10-04T01:27:37.611314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Shape & Memory ===\n",
      "Train Shape: (750000, 962), Test Shape: (250000, 960)\n",
      "Train Memory: 2.68 GB, Test Memory: 0.89 GB\n",
      "\n",
      "=== DTypes ===\n",
      "UInt32: 1\n",
      "Int32: 7\n",
      "Float32: 952\n",
      "Int8: 2\n"
     ]
    }
   ],
   "source": [
    "# === 特徴量エンジニアリング後の情報 ===\n",
    "train_mem, test_mem, n_cat = check_info(tr_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "526cdc6f-a8d1-42f6-b56f-0b8d640de52f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:27:39.144057Z",
     "iopub.status.busy": "2025-10-04T01:27:39.143749Z",
     "iopub.status.idle": "2025-10-04T01:27:48.594154Z",
     "shell.execute_reply": "2025-10-04T01:27:48.593801Z",
     "shell.execute_reply.started": "2025-10-04T01:27:39.144037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_df saved successfully to ../../artifacts/features/048/train.parquet\n",
      "test_df saved successfully to ../../artifacts/features/048/test.parquet\n"
     ]
    }
   ],
   "source": [
    "# === Save Overall Data ===\n",
    "tr_path = FEATURE_DIR / \"train.parquet\"\n",
    "test_path = FEATURE_DIR / \"test.parquet\"\n",
    "\n",
    "tr_df.write_parquet(tr_path)\n",
    "test_df.write_parquet(test_path)\n",
    "\n",
    "print(f\"tr_df saved successfully to {tr_path}\")\n",
    "print(f\"test_df saved successfully to {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d022ad-c3fa-4257-a39b-252ee38062a9",
   "metadata": {},
   "source": [
    "## Meta dataを保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9057009d-3ca6-4fb1-84d6-b8fc3eda83b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T01:27:59.314101Z",
     "iopub.status.busy": "2025-10-04T01:27:59.313940Z",
     "iopub.status.idle": "2025-10-04T01:27:59.318155Z",
     "shell.execute_reply": "2025-10-04T01:27:59.317789Z",
     "shell.execute_reply.started": "2025-10-04T01:27:59.314092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_id: 048\n",
      "created_at: 2025-10-04T10:27:59.315121+09:00\n",
      "train_paths: ['../../artifacts/features/048/train.parquet']\n",
      "test_paths: ['../../artifacts/features/048/test.parquet']\n",
      "level: l1\n",
      "train_shape: [750000, 962]\n",
      "test_shape: [250000, 960]\n",
      "memory: {'train': 2.6836059987545013, 'test': 0.8940696716308594}\n",
      "fold_column: [('skf/k=5/s=42@train', '5fold-s42')]\n",
      "cat_cols: None\n"
     ]
    }
   ],
   "source": [
    "JST = timezone(timedelta(hours=9))\n",
    "meta = {\n",
    "    \"data_id\": ID,\n",
    "    \"created_at\": datetime.now(JST).isoformat(),\n",
    "    \"train_paths\": [str(tr_path)],\n",
    "    \"test_paths\": [str(test_path)],\n",
    "    \"level\": LEVEL,\n",
    "    \"train_shape\": [tr_df.height, tr_df.width],\n",
    "    \"test_shape\": [test_df.height, test_df.width],\n",
    "    \"memory\": {\n",
    "        \"train\": train_mem,\n",
    "        \"test\": test_mem\n",
    "    },\n",
    "    \"fold_column\": pairs,\n",
    "    \"cat_cols\": n_cat if n_cat else None\n",
    "}\n",
    "\n",
    "with open(f\"{FEATURE_DIR}/meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "for k, v in meta.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.08",
   "language": "python",
   "name": "rapids-25.08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
