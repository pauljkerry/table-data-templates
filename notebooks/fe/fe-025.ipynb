{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872035b0-67f5-448c-a4ea-645990611106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanse/miniconda3/envs/autogluon/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb0c005-46e8-4dba-98e1-03410aa5b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pl.read_csv(\"../../input/train.csv\")\n",
    "test_data = pl.read_csv(\"../../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a22b8c-af03-4bb8-aff9-aad85b5acfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>age</th><th>job</th><th>marital</th><th>education</th><th>default</th><th>balance</th><th>housing</th><th>loan</th><th>contact</th><th>day</th><th>month</th><th>duration</th><th>campaign</th><th>pdays</th><th>previous</th><th>poutcome</th><th>y</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>42</td><td>&quot;technician&quot;</td><td>&quot;married&quot;</td><td>&quot;secondary&quot;</td><td>&quot;no&quot;</td><td>7</td><td>&quot;no&quot;</td><td>&quot;no&quot;</td><td>&quot;cellular&quot;</td><td>25</td><td>&quot;aug&quot;</td><td>117</td><td>3</td><td>-1</td><td>0</td><td>&quot;unknown&quot;</td><td>0</td></tr><tr><td>1</td><td>38</td><td>&quot;blue-collar&quot;</td><td>&quot;married&quot;</td><td>&quot;secondary&quot;</td><td>&quot;no&quot;</td><td>514</td><td>&quot;no&quot;</td><td>&quot;no&quot;</td><td>&quot;unknown&quot;</td><td>18</td><td>&quot;jun&quot;</td><td>185</td><td>1</td><td>-1</td><td>0</td><td>&quot;unknown&quot;</td><td>0</td></tr><tr><td>2</td><td>36</td><td>&quot;blue-collar&quot;</td><td>&quot;married&quot;</td><td>&quot;secondary&quot;</td><td>&quot;no&quot;</td><td>602</td><td>&quot;yes&quot;</td><td>&quot;no&quot;</td><td>&quot;unknown&quot;</td><td>14</td><td>&quot;may&quot;</td><td>111</td><td>2</td><td>-1</td><td>0</td><td>&quot;unknown&quot;</td><td>0</td></tr><tr><td>3</td><td>27</td><td>&quot;student&quot;</td><td>&quot;single&quot;</td><td>&quot;secondary&quot;</td><td>&quot;no&quot;</td><td>34</td><td>&quot;yes&quot;</td><td>&quot;no&quot;</td><td>&quot;unknown&quot;</td><td>28</td><td>&quot;may&quot;</td><td>10</td><td>2</td><td>-1</td><td>0</td><td>&quot;unknown&quot;</td><td>0</td></tr><tr><td>4</td><td>26</td><td>&quot;technician&quot;</td><td>&quot;married&quot;</td><td>&quot;secondary&quot;</td><td>&quot;no&quot;</td><td>889</td><td>&quot;yes&quot;</td><td>&quot;no&quot;</td><td>&quot;cellular&quot;</td><td>3</td><td>&quot;feb&quot;</td><td>902</td><td>1</td><td>-1</td><td>0</td><td>&quot;unknown&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 18)\n",
       "┌─────┬─────┬─────────────┬─────────┬───┬───────┬──────────┬──────────┬─────┐\n",
       "│ id  ┆ age ┆ job         ┆ marital ┆ … ┆ pdays ┆ previous ┆ poutcome ┆ y   │\n",
       "│ --- ┆ --- ┆ ---         ┆ ---     ┆   ┆ ---   ┆ ---      ┆ ---      ┆ --- │\n",
       "│ i64 ┆ i64 ┆ str         ┆ str     ┆   ┆ i64   ┆ i64      ┆ str      ┆ i64 │\n",
       "╞═════╪═════╪═════════════╪═════════╪═══╪═══════╪══════════╪══════════╪═════╡\n",
       "│ 0   ┆ 42  ┆ technician  ┆ married ┆ … ┆ -1    ┆ 0        ┆ unknown  ┆ 0   │\n",
       "│ 1   ┆ 38  ┆ blue-collar ┆ married ┆ … ┆ -1    ┆ 0        ┆ unknown  ┆ 0   │\n",
       "│ 2   ┆ 36  ┆ blue-collar ┆ married ┆ … ┆ -1    ┆ 0        ┆ unknown  ┆ 0   │\n",
       "│ 3   ┆ 27  ┆ student     ┆ single  ┆ … ┆ -1    ┆ 0        ┆ unknown  ┆ 0   │\n",
       "│ 4   ┆ 26  ┆ technician  ┆ married ┆ … ┆ -1    ┆ 0        ┆ unknown  ┆ 1   │\n",
       "└─────┴─────┴─────────────┴─────────┴───┴───────┴──────────┴──────────┴─────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f23c263-4c6c-4261-8ef7-d6b5bdba9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.rename({\"y\": \"target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5e910b-79c9-4c89-ba05-1aea7a2f4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5fee44e-eb7e-4119-825f-e3f2561c1953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250906_160451\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.10.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025\n",
      "CPU Count:          24\n",
      "Memory Avail:       21.73 GB / 23.47 GB (92.6%)\n",
      "Disk Space Avail:   848.43 GB / 1006.85 GB (84.3%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (750000 samples, 475.61 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/hanse/kaggle/binary-bank/notebooks/FE/AutogluonModels/ag-20250906_160451\"\n",
      "Train Data Rows:    750000\n",
      "Train Data Columns: 17\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22575.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 447.85 MB (2.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 8 | ['id', 'age', 'balance', 'day', 'duration', ...]\n",
      "\t\t('object', []) : 9 | ['job', 'marital', 'education', 'default', 'housing', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['job', 'marital', 'education', 'contact', 'month', ...]\n",
      "\t\t('int', [])       : 8 | ['id', 'age', 'balance', 'day', 'duration', ...]\n",
      "\t\t('int', ['bool']) : 3 | ['default', 'housing', 'loan']\n",
      "\t1.6s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 52.22 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.72s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 742500, Val Rows: 7500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ...\n",
      "\tFitting with cpus=12, gpus=0, mem=0.3/21.6 GB\n",
      "\t0.9345\t = Validation score   (accuracy)\n",
      "\t4.43s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tFitting with cpus=12, gpus=0, mem=0.3/21.5 GB\n",
      "\t0.9328\t = Validation score   (accuracy)\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\tFitting with cpus=24, gpus=0, mem=0.5/21.5 GB\n",
      "\t0.9319\t = Validation score   (accuracy)\n",
      "\t25.46s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tFitting with cpus=24, gpus=0, mem=0.5/21.2 GB\n",
      "\t0.9316\t = Validation score   (accuracy)\n",
      "\t29.97s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t0.9336\t = Validation score   (accuracy)\n",
      "\t69.68s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tFitting with cpus=24, gpus=0, mem=0.5/19.9 GB\n",
      "\t0.9163\t = Validation score   (accuracy)\n",
      "\t16.41s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tFitting with cpus=24, gpus=0, mem=0.5/19.5 GB\n",
      "\t0.9153\t = Validation score   (accuracy)\n",
      "\t19.28s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tFitting with cpus=12, gpus=0, mem=0.6/19.4 GB\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t278.34s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tFitting with cpus=12, gpus=0\n",
      "\t0.9352\t = Validation score   (accuracy)\n",
      "\t4.07s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting with cpus=12, gpus=0, mem=0.3/18.9 GB\n",
      "/home/hanse/miniconda3/envs/autogluon/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t0.936\t = Validation score   (accuracy)\n",
      "\t1301.41s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tFitting with cpus=12, gpus=0, mem=0.3/18.7 GB\n",
      "\t0.9367\t = Validation score   (accuracy)\n",
      "\t4.65s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBMLarge': 0.714, 'CatBoost': 0.286}\n",
      "\t0.9373\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1761.02s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 279637.7 rows/s (7500 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (7500 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/hanse/kaggle/binary-bank/notebooks/FE/AutogluonModels/ag-20250906_160451\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=\"target\").fit(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon",
   "language": "python",
   "name": "autogluon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
